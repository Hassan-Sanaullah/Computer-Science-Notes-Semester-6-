# The Basics of Intensity Transformations and Spatial Filtering

## Spatial Domain Processing
Spatial domain processing is defined by the transformation:
$$g(x, y) = T[f(x, y)]$$
where:  
- $f(x, y)$is the **input image**.  
- $g(x, y)$is the **output image**.  
- $T$is an **operator** applied to a neighborhood of point $(x, y)$.  

This operation can be performed:
- On a **single image** (primary focus).  
- Across **multiple images** (e.g., summing images for noise reduction, as discussed in Section 2.6).  

### Neighborhood Processing
- Each **pixel's output** depends on its **local neighborhood**.  
- A common example is a **$3 \times 3$neighborhood** centered at $(x_0, y_0)$.  
- The neighborhood **moves pixel by pixel** to generate the output image.  

#### Example: **Averaging Filter**
- Operator $T$computes the **average intensity** in a $3 \times 3$neighborhood:
  $$
  g(100, 150) = \frac{1}{9} \sum_{\text{neighbors}} f(100, 150)
  $$
- This process **smooths** the image by reducing noise.

## Intensity (Gray-Level) Transformations
If the neighborhood size is **$1 \times 1$**, transformation reduces to:
$$
s = T(r)
$$
where:
-  r is the **input intensity**.
- $s$is the **output intensity**.

### Contrast Stretching
- A transformation function **adjusts contrast** by:
  - **Darkening intensities** below a threshold $k$.
  - **Brightening intensities** above $k$.
- Example transformation function:
  - If $r < k$, $s$moves **toward black**.
  - If $r > k$, $s$moves **toward white**.

### Thresholding
- A **special case** of intensity transformation that converts an image to **binary**.
- Defined by:
  $$
  s =
  \begin{cases} 
  0, & r < k \\
  1, & r \geq k
  \end{cases}
  $$
- Used for **segmentation** (detailed in Chapter 10).

## Point vs. Neighborhood Processing
- **Point Processing:** Uses **only pixel intensity** at $(x, y)$(e.g., thresholding).  
- **Neighborhood Processing:** Uses **pixel and its neighbors** (e.g., averaging filter).  

These techniques are widely used for **image enhancement** and **segmentation**.

# Some Basic Intensity Transformation Functions

## Introduction
Intensity transformations are fundamental image processing techniques that modify pixel values.  
For an image with pixel intensities:
- **Before processing:** $r$
- **After processing:** $s$

The transformation is defined as:
$$
s = T(r)
$$
where $T$ maps each pixel intensity $r$ to a new intensity $s$.  
In digital images, transformation values are stored in a **lookup table (LUT)**:
- **For an 8-bit image**, the LUT has **256 entries**.

## Types of Intensity Transformations
There are three primary types of intensity transformation functions:

1. **Linear Transformations**
   - **Identity transformation**: $s = r$ (no change).
   - **Negative transformation**: $s = L - 1 - r$

2. **Logarithmic Transformations**
   - **Log transformation**: Enhances dark regions.
   - **Inverse-log transformation**: Expands bright regions.

3. **Power-Law Transformations**
   - **Nth power transformation**: Adjusts contrast.
   - **Nth root transformation**: Used for gamma correction.

## Image Negatives
The **negative transformation** is defined as:
$$
s = L - 1 - r
$$
where:
- $L$ is the **maximum intensity level** (e.g., 256 for an 8-bit image).
- This transformation **reverses intensity levels**, producing a **photographic negative**.

### Applications
- Enhancing details in **dark regions**.
- Improving visibility of **white or gray details** in **dominant black areas**.
- Example: **Medical imaging (mammograms)** to highlight **fine tissue structures**.

Negative transformations can help certain viewers analyze fine details more effectively.

# Log Transformations

## Definition
The general form of the **log transformation** is:
$$
s = c \log(1 + r)
$$
where:
- $s$ is the transformed pixel intensity.
- $r$ is the original pixel intensity ($r \geq 0$).
- $c$ is a scaling constant.

## Properties
- **Expands** low-intensity values.
- **Compresses** high-intensity values.
- **Spreads** dark pixels over a wider range.
- **Compresses** bright pixel values into a smaller range.
- **Reduces dynamic range**, making large intensity variations more displayable.

## Applications
1. **Enhancing dark regions** in an image.
2. **Reducing intensity variations** in images with a high dynamic range.
3. **Fourier Spectrum Visualization**:
   - Fourier spectrum values can range from **0 to $10^6$** or higher.
   - Directly displaying these values results in **loss of detail**.
   - **Applying log transformation** makes more details visible.
   - Example: Fourier spectrum processing (Chapter 4).

## Example
- Consider a **Fourier spectrum** with pixel values in **[0, 1.5 × 10^6]**.
- **Without transformation**:
  - High-intensity pixels dominate.
  - Most of the image appears **black**.
- **With log transformation** ($c = 1$):
  - Values are transformed into **[0, 6.2]**.
  - More intensity variations become **visible**.
  - The image displays **more details**.


# Power-Law (Gamma) Transformations

## Definition
The general form of the **power-law transformation** is:
$$
s = c r^\gamma
$$
where:
- $s$ is the transformed pixel intensity.
- $r$ is the original pixel intensity.
- $c$ and $\gamma$ are positive constants.

## Properties
- **Gamma ($\gamma$) controls brightness and contrast.**
  - If $\gamma < 1$: **Enhances dark regions** (spreads dark pixel values).
  - If $\gamma > 1$: **Enhances bright regions** (compresses bright pixel values).
  - If $\gamma = 1$: **Identity transformation** (no change).
- **More flexible than log transformation** for contrast adjustment.
- **Used for gamma correction** in display systems.

## Applications
### 1. **Gamma Correction**
- Many display devices (e.g., CRT monitors) have a nonlinear intensity response.
- CRT monitors often follow the power-law relation with $\gamma \approx 1.8 - 2.5$.
- To correct this, we apply a **pre-correction** transformation:
  $$
  s = r^{1/\gamma}
  $$
- **Example**: A monitor with $\gamma = 2.5$ makes an image appear **darker** than intended.
  - Applying gamma correction with $\gamma = 0.4$ restores the original brightness.

### 2. **Contrast Enhancement**
- **Dark images**: Use $\gamma < 1$ to brighten and enhance details.
- **Washed-out images**: Use $\gamma > 1$ to darken and increase contrast.

## Examples
### Example 1: MRI Contrast Enhancement
- **MRI scan** of a human spine with a **fracture dislocation**.
- Since the image is **mostly dark**, we apply gamma correction:
  - $\gamma = 0.6$ → Slight enhancement.
  - $\gamma = 0.4$ → **Best balance** between detail and contrast.
  - $\gamma = 0.3$ → **Washed-out effect** (too much brightness).

### Example 2: Aerial Image Processing
- **Aerial image** with a washed-out appearance.
- To **increase contrast**, we use higher values of $\gamma$:
  - $\gamma = 3.0$ → Improves visibility.
  - $\gamma = 4.0$ → **Better contrast** and sharpness.
  - $\gamma = 5.0$ → **Best clarity**, especially in finer details (e.g., airport runways).

## Summary Table
| $\gamma$  | Effect |
|--------------|--------------------------------|
| $< 1$   | Brightens dark images |
| $> 1$   | Darkens and enhances contrast in bright images |
| $= 1$   | No change (identity function) |
| $0.3$ - $0.6$ | Good for **enhancing dark images** (MRI scans, shadows) |
| $3.0$ - $5.0$ | Good for **enhancing bright images** (aerial photos) |

## Key Takeaways
- **Power-law transformation is essential** for gamma correction and contrast manipulation.
- **Adjusting $\gamma$** allows fine control over image brightness and visibility.
- **Choosing the right $\gamma$ value** is crucial for obtaining an optimal image.


# Piecewise Linear Transformation Functions

## Overview
- Piecewise linear functions provide an alternative approach to intensity transformations.
- These functions can be arbitrarily complex.
- Some transformations can only be effectively implemented using piecewise linear functions.
- **Advantage:** Flexible form allows for various transformations.
- **Disadvantage:** Requires significant user input.

---

## Contrast Stretching
- Used to enhance the contrast of low-contrast images.
- Low contrast may result from:
  - Poor illumination
  - Limited dynamic range in the sensor
  - Incorrect lens aperture settings
- **Objective:** Expands intensity levels to the full range of the display device.

### Transformation Function
- The function is controlled by two points: $(r_1, s_1)$ and $(r_2, s_2)$.
- **Cases:**
  - If $r_1 = s_1$ and $r_2 = s_2$, no intensity change occurs.
  - If $r_1 = r_2$, thresholding occurs, producing a **binary image**.
  - Intermediate values result in varying degrees of contrast enhancement.

### Example
1. **Low-contrast Image**: An 8-bit image with a limited intensity range.
2. **Contrast-Stretched Image**:
   - Set $(r_1, s_1) = (r_{\text{min}}, 0)$.
   - Set $(r_2, s_2) = (r_{\text{max}}, L - 1)$.
   - This maps the minimum and maximum intensity levels to the full range.
3. **Thresholded Image**:
   - Uses $(r_1, s_1) = (m, 0)$ and $(r_2, s_2) = (m, L - 1)$, where $m$ is the mean intensity.
   - Converts the image to binary based on mean intensity.

---

## Intensity-Level Slicing
- **Objective:** Highlights a specific range of intensities in an image.
- **Applications:**
  - Enhancing water masses in satellite images.
  - Detecting flaws in X-ray images.

### Methods
1. **Binary Slicing (Thresholding)**
   - Pixels in the selected intensity range are set to **white**.
   - All other intensities are set to **black**.
   - Results in a binary image.
2. **Gray-Level Slicing**
   - Pixels in the selected range are **brightened** or **darkened**.
   - Other intensities remain unchanged.

### Example
1. **Aortic Angiogram (Kidney Area)**
   - Objective: Enhance blood vessels using intensity slicing.
2. **Binary Slicing Result**
   - Blood vessels appear **white**.
   - Background appears **black**.
   - Useful for studying the shape of the contrast medium.
3. **Gray-Level Slicing Result**
   - The selected intensity band is set to **black**.
   - Other intensities remain unchanged.
   - Preserves gray-scale tonality, useful for measuring flow over time.

---

## Summary
- **Contrast Stretching**: Expands intensity range to enhance contrast.
- **Intensity-Level Slicing**: Highlights specific intensity ranges for analysis.
  - **Binary Slicing**: Converts the image into a binary format.
  - **Gray-Level Slicing**: Modifies intensity within a specific range while preserving others.


# Bit-Plane Slicing

## Overview
- Pixel values in a grayscale image are represented as **integers composed of bits**.
- In an **8-bit grayscale image**, each pixel is represented by 8 bits (one byte).
- **Objective:** Instead of highlighting intensity ranges, we highlight the contribution of specific bits to the overall image.
- **Method:** An image can be decomposed into **eight one-bit planes**, where:
  - **Plane 1** contains the least significant bit (LSB).
  - **Plane 8** contains the most significant bit (MSB).

---

## Importance of Bit Planes
- Higher-order bit planes (especially **planes 8 and 7**) contain most of the visually significant information.
- Lower-order bit planes contribute to finer intensity details.
- Example: A pixel with intensity **194** (binary: `11000010`) has:
  - MSB (`1`) contributing to major intensity information.
  - LSB (`0`) contributing to subtle variations.

---

## Extracting Bit Planes
- The **binary image of the 8th bit plane** is obtained by thresholding:
  - **Pixels with values 128-255** → **Mapped to 1 (white).**
  - **Pixels with values 0-127** → **Mapped to 0 (black).**
- Transformation functions for extracting other bit planes follow a similar pattern.

---

## Applications of Bit-Plane Decomposition
1. **Image Analysis**
   - Helps determine the importance of each bit in an image.
   - Useful for evaluating the adequacy of **bit quantization**.
   
2. **Image Compression**
   - Fewer bit planes can be used for image reconstruction.
   - Reduces storage requirements while preserving major image details.

---

## Image Reconstruction from Bit Planes
- Reconstructing an image using selected bit planes:
  - Each bit plane is multiplied by a weight:  
    $$\text{Bit Plane } n \times 2^{(n-1)}$$
  - The resulting planes are summed to obtain the grayscale image.

### Example:
1. **Using Only Planes 8 and 7**:
   - Bit plane 8 × 128  
   - Bit plane 7 × 64  
   - **Result:** Major features are restored, but the image appears **flat**.
   
2. **Adding Plane 6**:
   - Bit plane 6 × 32  
   - **Result:** Reduces false contouring, improves background details.

3. **Adding Plane 5**:
   - Bit plane 5 × 16  
   - **Result:** Further improves image quality, reduces storage by 50%.

### Conclusion:
- In this example, storing only the **four highest bit planes** is enough for acceptable image reconstruction.
- **Storage reduction:** 50% compared to the original image.

---

## Summary
- **Bit-Plane Slicing**: Decomposes an image into **eight binary bit planes**.
- **Higher-order bit planes**: Contain most of the significant visual information.
- **Lower-order bit planes**: Capture subtle intensity details.
- **Applications**:
  - Image analysis (bit importance, quantization).
  - Image compression (efficient storage, reduced redundancy).
- **Image Reconstruction**:
  - Uses weighted summation of bit planes.
  - Reducing the number of planes decreases storage but may affect quality.


# Histogram Processing  

## Histogram Definition  
Let $r_k$, for $k = 0, 1, 2, \dots, L-1$, denote the intensity levels of an **L-level digital image** $f(x,y)$.  

### Unnormalized Histogram  
The **unnormalized histogram** of $f(x,y)$ is defined as:  
$$
h(r_k) = n_k, \quad \text{for } k = 0, 1, 2, \dots, L-1
$$
where:  
- $n_k$ is the **number of pixels** with intensity $r_k$.  
- The subdivisions of the intensity scale are called **histogram bins**.  

### Normalized Histogram  
The **normalized histogram** of $f(x,y)$ is given by:  
$$
p(r_k) = \frac{h(r_k)}{MN} = \frac{n_k}{MN}
$$
where:  
- $M$ and $N$ are the number of image rows and columns, respectively.  
- The sum of all **$p(r_k)$ values** is always **1**.  
- The components of $p(r_k)$ are estimates of the **probabilities of intensity levels** occurring in an image.  

## Importance of Histograms in Image Processing  
- **Histogram manipulation** is a fundamental tool in image processing.  
- Histograms are **simple to compute** and **fast to implement in hardware**, making them suitable for **real-time image processing**.  

## Histogram Shape and Image Appearance  
Histogram shape provides **insights into image characteristics**:  

1. **Dark Image**  
   - Most **populated bins** are **concentrated on the lower (dark) end** of the intensity scale.  

2. **Light Image**  
   - Most populated bins are **biased toward the higher (bright) end** of the intensity scale.  

3. **Low Contrast Image**  
   - The histogram has a **narrow distribution**, typically **centered around the middle** of the intensity scale.  
   - The image appears **dull and washed out** (grayish look).  

4. **High Contrast Image**  
   - The histogram spans **a wide range of intensity levels**.  
   - The pixel distribution is **closer to uniform**, with **no extreme peaks**.  
   - The image exhibits a **high dynamic range**, showing **a variety of gray tones**.  

## Enhancing Image Contrast with Histogram Processing  
- An image with **pixels covering the entire intensity range** and **a uniform distribution** will have **high contrast** and exhibit **detailed gray levels**.  
- A transformation function can be developed to **automatically enhance contrast** using only the **input image histogram**.  


# Histogram Equalization

## Intensity Mapping

- The variable $r$ represents the intensities of an image to be processed, with $r$ in the range $[0, L-1]$, where:
  - $r = 0$ represents black
  - $r = L-1$ represents white

- The transformation function, $T(r)$, maps input intensity values to output intensity values, $s$. This transformation is expressed as:

  $$ s = T(r), \text{ where } 0 \leq r \leq L-1 $$

- **Assumptions** for the transformation function:
  1. $T(r)$ is a **monotonic increasing function** within the range $[0, L-1]$.
  2. The output intensity $s$ lies in the same range as $r$: $0 \leq T(r) \leq L-1$.

### Inverse Transformation

- The inverse transformation is defined as:

  $$ r = T^{-1}(s), \text{ where } 0 \leq s \leq L-1 $$

- **Modified Assumption** for inverse transformation:
  - $T(r)$ must be a **strictly monotonic increasing function** to ensure that each output intensity value corresponds to a unique input intensity.

### Function Mapping

- A **monotonic increasing function** allows multiple input values to map to the same output value. However, if we want to reverse the transformation, this can cause ambiguities. A strictly monotonic function ensures that each output maps uniquely to an input, both in the forward and inverse directions.

## Probability Distribution and Transformation

- The intensity of an image can be viewed as a random variable, $r$, in the interval $[0, L-1]$.

- The **probability density function (PDF)** of the input and output intensities are denoted as $p_r(r)$ and $p_s(s)$, respectively.

### Transformation of PDF

- If $p_r(r)$ is known, and the transformation function $T(r)$ is continuous and differentiable, the PDF of the transformed variable $s$ is given by:

  $$ p_s(s) = p_r(r) \left|\frac{dr}{ds}\right| $$

- For a specific transformation of the form:

  $$ s = T(r) = \int_0^r p_r(w) dw $$

  The output PDF can be computed as:

  $$ \frac{dp_s(s)}{ds} = \frac{p_r(r)}{dT(r)/dr} $$

## Example: PDF Transformation

- Consider a continuous intensity PDF:

  $$ p_r(r) = \begin{cases} 
    \frac{2r}{L^2} & 0 \leq r \leq L-1 \\
    0 & \text{otherwise}
  \end{cases} $$

  After applying the transformation, the output PDF $p_s(s)$ will always be uniform, regardless of the shape of $p_r(r)$.

### Discrete Intensity Levels

- In digital images, intensity levels are discrete. The probability of occurrence of intensity level $r_k$ is approximated as:

  $$ p_r(r_k) = \frac{n_k}{MN} $$

  where:
  - $n_k$ is the number of pixels with intensity $r_k$
  - $M$ and $N$ are the image dimensions (height and width)

- The discrete version of the transformation function is:

  $$ s_k = T(r_k) = \sum_j T(r_j) \cdot p_r(r_j) $$

  where $L$ is the number of possible intensity levels.

## Conclusion

- Histogram equalization is a process that transforms an image to have a uniform distribution of intensities, making it more visually distinct. By using the transformation function, input intensities are mapped to output intensities, resulting in better contrast and image quality.

# Histogram Equalization (Example 3.5)

Histogram equalization is a technique in image processing used to enhance the contrast of an image by adjusting the intensity levels.

## Problem Setup

Consider a 3-bit image (i.e., $L = 8$), with a size of $64 \times 64$ pixels ($MN = 4096$). The intensity levels are in the range $[0, 7]$. The image's histogram is shown in Figure 3.19(a), with the following intensity distribution (from Table 3.1):

| Intensity Level ($r_k$) | Pixel Count ($n_k$) | Probability ($p_r(r_k)$) |
|-------------------------|---------------------|--------------------------|
| 0                       | 790                 | 0.19                     |
| 1                       | 1023                | 0.25                     |
| 2                       | 850                 | 0.21                     |
| 3                       | 656                 | 0.16                     |
| 4                       | 329                 | 0.08                     |
| 5                       | 245                 | 0.06                     |
| 6                       | 122                 | 0.03                     |
| 7                       | 81                  | 0.02                     |

## Transformation Function

The histogram equalization transformation function is derived using the equation:

$$
s = T(r_k) = \sum_{j=0}^{r_k} p_r(r_j)
$$

Using this, we calculate the transformation values for different $r_k$:

- $T(0) = 0.0$
- $T(1) = 0.33$
- $T(2) = 0.55$
- $T(3) = 0.67$
- $T(4) = 0.23$
- $T(5) = 0.65$
- $T(6) = 0.86$
- $T(7) = 1.0$

The transformation function has a staircase shape, as shown in Figure 3.19(b). 

### Rounding Transformation Values

The transformed values are fractional. These are rounded to the nearest integer in the range $[0, 7]$:

- $s_0 = 1$
- $s_1 = 3$
- $s_2 = 5$
- $s_3 = 6$
- $s_4 = 6$
- $s_5 = 7$
- $s_6 = 7$
- $s_7 = 7$

These are the new intensity values for the histogram-equalized image.

## Equalized Histogram

In the equalized image:

- 790 pixels are mapped to $s_0 = 1$
- 1023 pixels are mapped to $s_1 = 3$
- 850 pixels are mapped to $s_2 = 5$
- 985 pixels (656 + 329) are mapped to $s_3 = 6$
- 448 pixels (245 + 122 + 81) are mapped to $s_4 = 7$

The normalized histogram for the equalized image (Figure 3.19(c)) is plotted based on these new values.

## Contrast Enhancement

Histogram equalization spreads the histogram of the input image so that the intensity levels of the equalized image span a wider range of the intensity scale. This results in **contrast enhancement**.

## Automatic Process

One of the key features of histogram equalization is that it is **automatic**. The process is entirely based on the input image's histogram, so no additional parameters are required. This makes it a fully automatic process for enhancing contrast.

## Inverse Transformation

The inverse transformation from the equalized image intensity values $s$ back to the original intensity values $r$ is denoted by:

$$
r = T^{-1}(s_k)
$$

This inverse transformation works only if all intensity levels are present in the input image, meaning no histogram bins are empty. While the inverse transformation is not directly used in histogram equalization, it plays a role in **histogram matching**.

# Local Histogram Equalization

Local histogram equalization is a technique used to enhance the details within a local region of an image, as opposed to global histogram equalization, which affects the entire image. It is especially useful when there are small objects embedded in regions with similar intensity values that global histogram equalization cannot reveal effectively.

## Example: 8-bit Image with Dark Squares

Consider an 8-bit image of size $512 \times 512$ with five black squares on a light gray background. The image has slight noise, but the noise is imperceptible to the human eye. 

- **Figure 3.26(a)**: The original image with dark squares and a light gray background.

### Global Histogram Equalization

Global histogram equalization attempts to equalize the histogram for the entire image:

- **Figure 3.26(b)**: Result of global histogram equalization.
    - **Issue**: In smooth, noisy regions, global equalization tends to enhance the noise, but does not reveal any significant new details in the dark squares. The intensity levels in the dark squares and the objects within them are too close for global equalization to distinguish effectively.

### Local Histogram Equalization

Local histogram equalization operates over a local region of the image, using a neighborhood of size $3 \times 3$ to adjust the histogram within this region. It is especially useful when small details are lost in the global process.

- **Figure 3.26(c)**: Result of local histogram equalization with a $3 \times 3$ neighborhood.
    - **Advantage**: This technique reveals significant detail within the dark squares that were previously invisible. The objects embedded in the dark squares are now visible because their intensity values are enhanced locally, which was not possible with global histogram equalization.
    - **Reason**: The objects’ intensity values are too similar to the surrounding dark squares and are too small to influence the global histogram significantly.

## Conclusion

Local histogram equalization enhances small details in regions that may be overlooked by global equalization. It is especially effective when working with small objects or when intensity values within a specific region are too similar to their surroundings.
